{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 325>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mSubmit\u001b[39m(\u001b[38;5;28mself\u001b[39m, event):\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAdd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontroller)\n\u001b[1;32m--> 325\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[43mApplication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m app\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m    327\u001b[0m app\u001b[38;5;241m.\u001b[39mcam\u001b[38;5;241m.\u001b[39mrelease()\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mApplication.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes \u001b[38;5;241m=\u001b[39m {} \n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m F \u001b[38;5;129;01min\u001b[39;00m (RecognisePage, AddNewPersonPage, StoreNewPersonImage):\n\u001b[1;32m--> 103\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes[F] \u001b[38;5;241m=\u001b[39m frame\n\u001b[0;32m    105\u001b[0m     frame\u001b[38;5;241m.\u001b[39mgrid(row \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, column \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, sticky \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnsew\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mRecognisePage.__init__\u001b[1;34m(self, parent, controller)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcam_capture \u001b[38;5;241m=\u001b[39m ttk\u001b[38;5;241m.\u001b[39mLabel(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcam_capture\u001b[38;5;241m.\u001b[39mgrid(row \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, column \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, padx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, pady \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCamera\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Add New Person Button\u001b[39;00m\n\u001b[0;32m    143\u001b[0m style \u001b[38;5;241m=\u001b[39m ttk\u001b[38;5;241m.\u001b[39mStyle()\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mRecognisePage.Camera\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m         largest_label \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontroller\u001b[38;5;241m.\u001b[39mregistered_label[i]\n\u001b[0;32m    179\u001b[0m cv\u001b[38;5;241m.\u001b[39mrectangle(frame, (x, y), (x\u001b[38;5;241m+\u001b[39mw, y\u001b[38;5;241m+\u001b[39mh), (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(\u001b[43mlargest_similarity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.7\u001b[39m):\n\u001b[0;32m    181\u001b[0m     frame \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mputText(frame, largest_label, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m25\u001b[39m), cv\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m, cv\u001b[38;5;241m.\u001b[39mLINE_AA)\n\u001b[0;32m    182\u001b[0m     frame \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mround\u001b[39m(largest_similarity\u001b[38;5;241m.\u001b[39mitem(),\u001b[38;5;241m3\u001b[39m)), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m50\u001b[39m), cv\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m, cv\u001b[38;5;241m.\u001b[39mLINE_AA)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import walk\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import cm\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import tkinter.messagebox as msgbox\n",
    "from tkinter import font\n",
    "from PIL import ImageTk, Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Class to store the loaded Siamese Network model\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # call super constructor\n",
    "        super().__init__()\n",
    "        # fully connected layer\n",
    "        self.fc1 = nn.Linear(in_features=128*2, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=1024)\n",
    "        self.fc3 = nn.Linear(in_features=1024, out_features=1)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat([x1, x2], dim=1) #concatenate 2 feature vector from 2 images (512D + 512D)\n",
    "        # fc layer\n",
    "        x = F.relu(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, p=0.5)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = F.dropout(x, p=0.5)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Preprocessing for images\n",
    "recog_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "# Model to detect human face in preprocessing step\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "resNet = torch.load(\"saved_best_resNet34.pt\") \n",
    "siameseNet = torch.load(\"saved_best_siameseNet.pt\")\n",
    "\n",
    "# Check GPU availability and use if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "siameseNet = siameseNet.to(device)\n",
    "siameseNet.eval()\n",
    "resNet = resNet.to(device)\n",
    "resNet.eval()\n",
    "\n",
    "class Application(tk.Tk):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "        self.title('Face Recognition App')\n",
    "        \n",
    "        # Store features of registered faces\n",
    "        self.registered_label = []\n",
    "        self.registered = []\n",
    "        \n",
    "        # Directory that stores registered faces\n",
    "        path = os.getcwd()+\"\\Registered Faces\"\n",
    "\n",
    "        # Check if folder exists\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        # Go to the directory\n",
    "        os.chdir(path)\n",
    "        \n",
    "        # Get the features of all registered faces\n",
    "        self.initialize_registered_faces()\n",
    "        \n",
    "        # Stored captured image\n",
    "        self.captured_image = None\n",
    "        \n",
    "        # Initialise camera\n",
    "        self.cam = cv.VideoCapture(0)\n",
    "        \n",
    "        # Create a container\n",
    "        container = tk.Frame(self) \n",
    "        container.pack(side = \"top\", fill = \"both\", expand = True)\n",
    "        container.grid_rowconfigure(0, weight = 1)\n",
    "        container.grid_columnconfigure(0, weight = 1)\n",
    "  \n",
    "        # Store frames to an empty array\n",
    "        self.frames = {} \n",
    "        for F in (RecognisePage, AddNewPersonPage, StoreNewPersonImage):\n",
    "            frame = F(container, self)\n",
    "            self.frames[F] = frame\n",
    "            frame.grid(row = 0, column = 0, sticky =\"nsew\")\n",
    "        self.show_frame(RecognisePage)\n",
    "  \n",
    "    # Switch frame\n",
    "    def show_frame(self, cont):\n",
    "        self.frame = cont\n",
    "        frame = self.frames[cont]\n",
    "        frame.tkraise()\n",
    "    \n",
    "    def initialize_registered_faces(self):\n",
    "        self.registered_label = []\n",
    "        self.registered = []\n",
    "        faces = []\n",
    "        for(dirpath, dirnames, filenames) in walk(os.getcwd()):\n",
    "            faces.extend(filenames)\n",
    "        for i in range (len(faces)):\n",
    "            img = Image.open(faces[i]).convert('RGB')\n",
    "            img = recog_transform(img)\n",
    "            img = img.unsqueeze(0)\n",
    "            img = img.to(device)\n",
    "            feature = resNet(img)\n",
    "            self.registered_label.append(Path(faces[i]).stem)\n",
    "            self.registered.append(feature)\n",
    "        \n",
    "class RecognisePage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.controller = controller\n",
    "        \n",
    "        # Initialise camera\n",
    "        self.cam = controller.cam\n",
    "        \n",
    "        # Create tkinter label to show captured image\n",
    "        self.cam_capture = ttk.Label(self)\n",
    "        self.cam_capture.grid(row = 0, column = 1, padx = 10, pady = 10)\n",
    "        self.Camera()\n",
    "\n",
    "        # Add New Person Button\n",
    "        style = ttk.Style()\n",
    "        style.configure('my.TButton', font=(\"Verdana\", 20))\n",
    "        AddPersonBtn = ttk.Button(self, text =\"Add New Person\", style='my.TButton', command = lambda : controller.show_frame(AddNewPersonPage))\n",
    "        AddPersonBtn.grid(row = 1, column = 1, padx = 10, pady = 10)\n",
    "          \n",
    "    def Camera(self):\n",
    "        _, frame = self.cam.read()\n",
    "        # Preprocess the camera capture:\n",
    "        # - Resize if the captured image is larger than window size\n",
    "        # - Flip the captured image horizontally\n",
    "        # - Change image from BGR to RGB format\n",
    "        width = frame.shape[1]\n",
    "        if(width > 650):\n",
    "            height = frame.shape[0]\n",
    "            scale = width/650\n",
    "            frame = cv.resize(frame, (650, int(height/scale)))\n",
    "        frame = cv.flip(frame, 1)\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # Detect human face\n",
    "        faces = face_cascade.detectMultiScale(frame, 1.1, 4)\n",
    "        for (x, y, w, h) in faces:\n",
    "#             cropped = frame[y:y+h, x:x+w]\n",
    "            cropped = frame\n",
    "            cropped = Image.fromarray(cropped.astype('uint8'), 'RGB')\n",
    "            cropped = recog_transform(cropped)\n",
    "            cropped = cropped.unsqueeze(0)\n",
    "            cropped = cropped.to(device)\n",
    "            feature = resNet(cropped)\n",
    "            largest_similarity = 0\n",
    "            largest_label = \"\"\n",
    "            for i in range (len(self.controller.registered_label)):\n",
    "                similarity = siameseNet(feature, self.controller.registered[i])\n",
    "                if (similarity >= largest_similarity):\n",
    "                    largest_similarity = similarity\n",
    "                    largest_label =  self.controller.registered_label[i]\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            if(largest_similarity.item() > 0.7):\n",
    "                frame = cv.putText(frame, largest_label, (0, 25), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "                frame = cv.putText(frame, str(round(largest_similarity.item(),3)), (0, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "            else:\n",
    "                frame = cv.putText(frame, \"Unknown\", (0, 25), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv.LINE_AA)\n",
    "                \n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # Display the image\n",
    "        frame = Image.fromarray(frame)\n",
    "        imgtk = ImageTk.PhotoImage(image = frame)\n",
    "        self.cam_capture.imgtk = imgtk\n",
    "        self.cam_capture.configure(image=imgtk)\n",
    "        # Loop\n",
    "        self.stream = self.cam_capture.after(100, self.Camera)\n",
    "\n",
    "        \n",
    "# second window frame page1\n",
    "class AddNewPersonPage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.controller = controller\n",
    "        \n",
    "        #Store captured image\n",
    "        self.last_image = None\n",
    "        \n",
    "        # Initialise camera\n",
    "        self.cam = controller.cam\n",
    "        \n",
    "        # Create tkinter label to show captured image\n",
    "        self.cam_capture = ttk.Label(self)\n",
    "        self.cam_capture.grid(row = 0, column = 1, padx = 10, pady = 10)\n",
    "        self.Camera()\n",
    "  \n",
    "        # Define word style\n",
    "        style = ttk.Style()\n",
    "        style.configure('my.TButton', font=(\"Verdana\", 20))\n",
    "\n",
    "        # Capture image and register new face\n",
    "        CaptureBtn = ttk.Button(self, text =\"Capture\", style='my.TButton', command = lambda : self.Capture(controller))\n",
    "        CaptureBtn.grid(row = 1, column = 1, padx = 10, pady = 10)\n",
    "        \n",
    "        # Back to recognise page\n",
    "        BackBtn = ttk.Button(self, text =\"Back\", style='my.TButton', command = lambda : controller.show_frame(RecognisePage))\n",
    "        BackBtn.grid(row = 2, column = 1, padx = 10, pady = 10)\n",
    "  \n",
    "    def Camera(self):\n",
    "        _, frame = self.cam.read()\n",
    "        self.last_image = frame\n",
    "        # Preprocess the camera capture:\n",
    "        # - Resize if the captured image is larger than window size\n",
    "        # - Flip the captured image horizontally\n",
    "        # - Change image from BGR to RGB format        \n",
    "        width = frame.shape[1]\n",
    "        if(width > 650):\n",
    "            height = frame.shape[0]\n",
    "            scale = width/650\n",
    "            frame = cv.resize(frame, (650, int(height/scale)))\n",
    "        frame = cv.flip(frame, 1)\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display the image\n",
    "        frame = Image.fromarray(frame)\n",
    "        imgtk = ImageTk.PhotoImage(image = frame)\n",
    "        self.cam_capture.imgtk = imgtk\n",
    "        self.cam_capture.configure(image=imgtk)\n",
    "        # Loop\n",
    "        self.stream = self.cam_capture.after(100, self.Camera)\n",
    "    \n",
    "    def Capture(self, controller):\n",
    "        controller.captured_image = self.last_image\n",
    "        controller.show_frame(StoreNewPersonImage)\n",
    "        \n",
    "# third window frame page2\n",
    "class StoreNewPersonImage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.controller = controller\n",
    "        \n",
    "        # Create tkinter label to show captured image\n",
    "        self.imglabel = ttk.Label(self)\n",
    "        self.imglabel.grid(row = 0, column = 1, columnspan=5, padx = 10, pady = 10)\n",
    "        \n",
    "        # Define word style\n",
    "        style = ttk.Style()\n",
    "        style.configure('my.TButton', font=(\"Verdana\", 20))\n",
    "    \n",
    "        # Enter text label\n",
    "        EnterNameLabel = ttk.Label(self, text =\"Enter name:\", font=(\"Verdana\", 20))\n",
    "        EnterNameLabel.grid(row = 1, column = 2, padx = 10, pady = 10)\n",
    "    \n",
    "        # Input to get name\n",
    "        self.inputtxt = tk.Text(self, height = 1, width = 30)\n",
    "        self.inputtxt.configure(wrap=None)\n",
    "        self.inputtxt.grid(row = 1, column = 4, padx = 10, pady = 10)\n",
    "        \n",
    "        # Press enter key to submit\n",
    "        self.inputtxt.bind('<Return>', self.Submit)\n",
    "        \n",
    "        # Back to capture image page\n",
    "        BackBtn = ttk.Button(self, text =\"Back\", style='my.TButton', command = lambda : controller.show_frame(AddNewPersonPage))\n",
    "        BackBtn.grid(row = 2, column = 2, padx = 10, pady = 10)\n",
    "    \n",
    "        # Button to add Person\n",
    "        AddBtn = ttk.Button(self, text =\"Add\", style='my.TButton', command = lambda : self.Add(controller))\n",
    "        AddBtn.grid(row = 2, column = 4, padx = 10, pady = 10)\n",
    "        \n",
    "    def tkraise(self, aboveThis=None):\n",
    "        #Change image\n",
    "        frame = self.controller.captured_image\n",
    "        width = frame.shape[1]\n",
    "        if(width > 650):\n",
    "            height = frame.shape[0]\n",
    "            scale = width/650\n",
    "            frame = cv.resize(frame, (650, int(height/scale)))\n",
    "        frame = cv.flip(frame, 1)\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        frame = Image.fromarray(frame)\n",
    "        imgtk = ImageTk.PhotoImage(image = frame)\n",
    "        self.imglabel.imgtk = imgtk\n",
    "        self.imglabel.configure(image=imgtk)\n",
    "\n",
    "        # Call the real .tkraise\n",
    "        super().tkraise(aboveThis)\n",
    "\n",
    "    def Add(self, controller):\n",
    "        # Get name\n",
    "        inputName = self.inputtxt.get(\"1.0\",\"end-1c\").strip()\n",
    "        \n",
    "        # Check user input\n",
    "        if (inputName == \"\"):\n",
    "            msgbox.showerror(title = \"Failed\", message = \"Please Input Name!\")\n",
    "        else:\n",
    "            msgbox.showinfo(title = \"Success\", message = \"Face Added Successfully\")\n",
    "            self.inputtxt.delete(\"1.0\",\"end\")\n",
    "\n",
    "            # Save image\n",
    "            cv.imwrite(inputName + \".png\", controller.captured_image)\n",
    "        \n",
    "            controller.show_frame(RecognisePage)\n",
    "            controller.initialize_registered_faces()\n",
    "    \n",
    "    def Submit(self, event):\n",
    "        self.Add(self.controller)\n",
    "\n",
    "app = Application()\n",
    "app.mainloop()\n",
    "app.cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

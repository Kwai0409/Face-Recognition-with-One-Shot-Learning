{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved_best_resNet34.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 52>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Model to detect human face in preprocessing step\u001b[39;00m\n\u001b[0;32m     50\u001b[0m face_cascade \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mCascadeClassifier(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m resNet \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_best_resNet34.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     53\u001b[0m siameseNet \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_best_siameseNet.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Check GPU availability and use if available\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_best_resNet34.pt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import walk\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import cm\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import tkinter.messagebox as msgbox\n",
    "from tkinter import font\n",
    "from PIL import ImageTk, Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Class to store the loaded Siamese Network model\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # call super constructor\n",
    "        super().__init__()\n",
    "        # fully connected layer\n",
    "        self.fc1 = nn.Linear(in_features=128*2, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=1024)\n",
    "        self.fc3 = nn.Linear(in_features=1024, out_features=1)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat([x1, x2], dim=1) #concatenate 2 feature vector from 2 images (512D + 512D)\n",
    "        # fc layer\n",
    "        x = F.relu(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, p=0.5)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = F.dropout(x, p=0.5)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Preprocessing for images\n",
    "recog_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "# Model to detect human face in preprocessing step\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "resNet = torch.load(\"saved_best_resNet34.pt\") \n",
    "siameseNet = torch.load(\"saved_best_siameseNet.pt\")\n",
    "\n",
    "# Check GPU availability and use if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "siameseNet = siameseNet.to(device)\n",
    "siameseNet.eval()\n",
    "resNet = resNet.to(device)\n",
    "resNet.eval()\n",
    "\n",
    "class Application(tk.Tk):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "        self.title('Face Recognition App')\n",
    "        \n",
    "        # Store features of registered faces\n",
    "        self.registered_label = []\n",
    "        self.registered = []\n",
    "        \n",
    "        # Directory that stores registered faces\n",
    "        path = os.getcwd()+\"\\Registered Faces\"\n",
    "\n",
    "        # Check if folder exists\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        # Go to the directory\n",
    "        os.chdir(path)\n",
    "        \n",
    "        # Get the features of all registered faces\n",
    "        self.initialize_registered_faces()\n",
    "        \n",
    "        # Stored captured image\n",
    "        self.captured_image = None\n",
    "        \n",
    "        # Initialise camera\n",
    "        self.cam = cv.VideoCapture(0)\n",
    "        \n",
    "        # Create a container\n",
    "        container = tk.Frame(self) \n",
    "        container.pack(side = \"top\", fill = \"both\", expand = True)\n",
    "        container.grid_rowconfigure(0, weight = 1)\n",
    "        container.grid_columnconfigure(0, weight = 1)\n",
    "  \n",
    "        # Store frames to an empty array\n",
    "        self.frames = {} \n",
    "        for F in (RecognisePage, AddNewPersonPage, StoreNewPersonImage):\n",
    "            frame = F(container, self)\n",
    "            self.frames[F] = frame\n",
    "            frame.grid(row = 0, column = 0, sticky =\"nsew\")\n",
    "        self.show_frame(RecognisePage)\n",
    "  \n",
    "    # Switch frame\n",
    "    def show_frame(self, cont):\n",
    "        self.frame = cont\n",
    "        frame = self.frames[cont]\n",
    "        frame.tkraise()\n",
    "    \n",
    "    def initialize_registered_faces(self):\n",
    "        self.registered_label = []\n",
    "        self.registered = []\n",
    "        faces = []\n",
    "        for(dirpath, dirnames, filenames) in walk(os.getcwd()):\n",
    "            faces.extend(filenames)\n",
    "        for i in range (len(faces)):\n",
    "            img = Image.open(faces[i]).convert('RGB')\n",
    "            img = recog_transform(img)\n",
    "            img = img.unsqueeze(0)\n",
    "            img = img.to(device)\n",
    "            feature = resNet(img)\n",
    "            self.registered_label.append(Path(faces[i]).stem)\n",
    "            self.registered.append(feature)\n",
    "        \n",
    "class RecognisePage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.controller = controller\n",
    "        \n",
    "        # Initialise camera\n",
    "        self.cam = controller.cam\n",
    "        \n",
    "        # Create tkinter label to show captured image\n",
    "        self.cam_capture = ttk.Label(self)\n",
    "        self.cam_capture.grid(row = 0, column = 1, padx = 10, pady = 10)\n",
    "        self.Camera()\n",
    "\n",
    "        # Add New Person Button\n",
    "        style = ttk.Style()\n",
    "        style.configure('my.TButton', font=(\"Verdana\", 20))\n",
    "        AddPersonBtn = ttk.Button(self, text =\"Add New Person\", style='my.TButton', command = lambda : controller.show_frame(AddNewPersonPage))\n",
    "        AddPersonBtn.grid(row = 1, column = 1, padx = 10, pady = 10)\n",
    "          \n",
    "    def Camera(self):\n",
    "        _, frame = self.cam.read()\n",
    "        # Preprocess the camera capture:\n",
    "        # - Resize if the captured image is larger than window size\n",
    "        # - Flip the captured image horizontally\n",
    "        # - Change image from BGR to RGB format\n",
    "        width = frame.shape[1]\n",
    "        if(width > 650):\n",
    "            height = frame.shape[0]\n",
    "            scale = width/650\n",
    "            frame = cv.resize(frame, (650, int(height/scale)))\n",
    "        frame = cv.flip(frame, 1)\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # Detect human face\n",
    "        faces = face_cascade.detectMultiScale(frame, 1.1, 4)\n",
    "        for (x, y, w, h) in faces:\n",
    "#             cropped = frame[y:y+h, x:x+w]\n",
    "            cropped = frame\n",
    "            cropped = Image.fromarray(cropped.astype('uint8'), 'RGB')\n",
    "            cropped = recog_transform(cropped)\n",
    "            cropped = cropped.unsqueeze(0)\n",
    "            cropped = cropped.to(device)\n",
    "            feature = resNet(cropped)\n",
    "            largest_similarity = 0\n",
    "            largest_label = \"\"\n",
    "            for i in range (len(self.controller.registered_label)):\n",
    "                similarity = siameseNet(feature, self.controller.registered[i])\n",
    "                if (similarity >= largest_similarity):\n",
    "                    largest_similarity = similarity\n",
    "                    largest_label =  self.controller.registered_label[i]\n",
    "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            if(largest_similarity > 0.7):\n",
    "                frame = cv.putText(frame, largest_label, (0, 25), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv.LINE_AA)\n",
    "                frame = cv.putText(frame, str(round(largest_similarity.item(),3)), (0, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv.LINE_AA)\n",
    "            else:\n",
    "                frame = cv.putText(frame, \"Unknown\", (0, 25), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv.LINE_AA)\n",
    "                \n",
    "#---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # Display the image\n",
    "        frame = Image.fromarray(frame)\n",
    "        imgtk = ImageTk.PhotoImage(image = frame)\n",
    "        self.cam_capture.imgtk = imgtk\n",
    "        self.cam_capture.configure(image=imgtk)\n",
    "        # Loop\n",
    "        self.stream = self.cam_capture.after(100, self.Camera)\n",
    "\n",
    "        \n",
    "# second window frame page1\n",
    "class AddNewPersonPage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.controller = controller\n",
    "        \n",
    "        #Store captured image\n",
    "        self.last_image = None\n",
    "        \n",
    "        # Initialise camera\n",
    "        self.cam = controller.cam\n",
    "        \n",
    "        # Create tkinter label to show captured image\n",
    "        self.cam_capture = ttk.Label(self)\n",
    "        self.cam_capture.grid(row = 0, column = 1, padx = 10, pady = 10)\n",
    "        self.Camera()\n",
    "  \n",
    "        # Define word style\n",
    "        style = ttk.Style()\n",
    "        style.configure('my.TButton', font=(\"Verdana\", 20))\n",
    "\n",
    "        # Capture image and register new face\n",
    "        CaptureBtn = ttk.Button(self, text =\"Capture\", style='my.TButton', command = lambda : self.Capture(controller))\n",
    "        CaptureBtn.grid(row = 1, column = 1, padx = 10, pady = 10)\n",
    "        \n",
    "        # Back to recognise page\n",
    "        BackBtn = ttk.Button(self, text =\"Back\", style='my.TButton', command = lambda : controller.show_frame(RecognisePage))\n",
    "        BackBtn.grid(row = 2, column = 1, padx = 10, pady = 10)\n",
    "  \n",
    "    def Camera(self):\n",
    "        _, frame = self.cam.read()\n",
    "        self.last_image = frame\n",
    "        # Preprocess the camera capture:\n",
    "        # - Resize if the captured image is larger than window size\n",
    "        # - Flip the captured image horizontally\n",
    "        # - Change image from BGR to RGB format        \n",
    "        width = frame.shape[1]\n",
    "        if(width > 650):\n",
    "            height = frame.shape[0]\n",
    "            scale = width/650\n",
    "            frame = cv.resize(frame, (650, int(height/scale)))\n",
    "        frame = cv.flip(frame, 1)\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display the image\n",
    "        frame = Image.fromarray(frame)\n",
    "        imgtk = ImageTk.PhotoImage(image = frame)\n",
    "        self.cam_capture.imgtk = imgtk\n",
    "        self.cam_capture.configure(image=imgtk)\n",
    "        # Loop\n",
    "        self.stream = self.cam_capture.after(100, self.Camera)\n",
    "    \n",
    "    def Capture(self, controller):\n",
    "        controller.captured_image = self.last_image\n",
    "        controller.show_frame(StoreNewPersonImage)\n",
    "        \n",
    "# third window frame page2\n",
    "class StoreNewPersonImage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.controller = controller\n",
    "        \n",
    "        # Create tkinter label to show captured image\n",
    "        self.imglabel = ttk.Label(self)\n",
    "        self.imglabel.grid(row = 0, column = 1, columnspan=5, padx = 10, pady = 10)\n",
    "        \n",
    "        # Define word style\n",
    "        style = ttk.Style()\n",
    "        style.configure('my.TButton', font=(\"Verdana\", 20))\n",
    "    \n",
    "        # Enter text label\n",
    "        EnterNameLabel = ttk.Label(self, text =\"Enter name:\", font=(\"Verdana\", 20))\n",
    "        EnterNameLabel.grid(row = 1, column = 2, padx = 10, pady = 10)\n",
    "    \n",
    "        # Input to get name\n",
    "        self.inputtxt = tk.Text(self, height = 1, width = 30)\n",
    "        self.inputtxt.configure(wrap=None)\n",
    "        self.inputtxt.grid(row = 1, column = 4, padx = 10, pady = 10)\n",
    "        \n",
    "        # Press enter key to submit\n",
    "        self.inputtxt.bind('<Return>', self.Submit)\n",
    "        \n",
    "        # Back to capture image page\n",
    "        BackBtn = ttk.Button(self, text =\"Back\", style='my.TButton', command = lambda : controller.show_frame(AddNewPersonPage))\n",
    "        BackBtn.grid(row = 2, column = 2, padx = 10, pady = 10)\n",
    "    \n",
    "        # Button to add Person\n",
    "        AddBtn = ttk.Button(self, text =\"Add\", style='my.TButton', command = lambda : self.Add(controller))\n",
    "        AddBtn.grid(row = 2, column = 4, padx = 10, pady = 10)\n",
    "        \n",
    "    def tkraise(self, aboveThis=None):\n",
    "        #Change image\n",
    "        frame = self.controller.captured_image\n",
    "        width = frame.shape[1]\n",
    "        if(width > 650):\n",
    "            height = frame.shape[0]\n",
    "            scale = width/650\n",
    "            frame = cv.resize(frame, (650, int(height/scale)))\n",
    "        frame = cv.flip(frame, 1)\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        \n",
    "        frame = Image.fromarray(frame)\n",
    "        imgtk = ImageTk.PhotoImage(image = frame)\n",
    "        self.imglabel.imgtk = imgtk\n",
    "        self.imglabel.configure(image=imgtk)\n",
    "\n",
    "        # Call the real .tkraise\n",
    "        super().tkraise(aboveThis)\n",
    "\n",
    "    def Add(self, controller):\n",
    "        # Get name\n",
    "        inputName = self.inputtxt.get(\"1.0\",\"end-1c\").strip()\n",
    "        \n",
    "        # Check user input\n",
    "        if (inputName == \"\"):\n",
    "            msgbox.showerror(title = \"Failed\", message = \"Please Input Name!\")\n",
    "        else:\n",
    "            msgbox.showinfo(title = \"Success\", message = \"Face Added Successfully\")\n",
    "            self.inputtxt.delete(\"1.0\",\"end\")\n",
    "\n",
    "            # Save image\n",
    "            cv.imwrite(inputName + \".png\", controller.captured_image)\n",
    "        \n",
    "            controller.show_frame(RecognisePage)\n",
    "            controller.initialize_registered_faces()\n",
    "    \n",
    "    def Submit(self, event):\n",
    "        self.Add(self.controller)\n",
    "\n",
    "app = Application()\n",
    "app.mainloop()\n",
    "app.cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
